name: Deduplicate Archive

on:
  workflow_dispatch:  # Manual trigger only

jobs:
  deduplicate:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Find and remove duplicates
        run: |
          python3 << 'EOF'
          import os
          import hashlib
          from pathlib import Path
          from collections import defaultdict
          
          # File priority (higher = keep)
          PRIORITY = {'.md': 5, '.html': 4, '.txt': 3, '.docx': 2, '.pdf': 1, '.zip': 0}
          
          def get_hash(filepath):
              """Calculate SHA256 hash of file"""
              sha256 = hashlib.sha256()
              try:
                  with open(filepath, 'rb') as f:
                      for chunk in iter(lambda: f.read(8192), b''):
                          sha256.update(chunk)
                  return sha256.hexdigest()
              except:
                  return None
          
          def get_priority(filepath):
              """Get file priority based on extension"""
              ext = Path(filepath).suffix.lower()
              return PRIORITY.get(ext, -1)
          
          # Scan all files
          print("üîç Scanning repository...")
          files_by_hash = defaultdict(list)
          total_files = 0
          
          for root, dirs, files in os.walk('.'):
              # Skip .git and .github directories
              if '.git' in root:
                  continue
              
              for file in files:
                  filepath = os.path.join(root, file)
                  file_hash = get_hash(filepath)
                  
                  if file_hash:
                      files_by_hash[file_hash].append(filepath)
                      total_files += 1
          
          print(f"üìä Total files scanned: {total_files}")
          
          # Find duplicates
          duplicates = {h: files for h, files in files_by_hash.items() if len(files) > 1}
          
          if not duplicates:
              print("‚úÖ No duplicates found!")
              exit(0)
          
          print(f"‚ö†Ô∏è  Found {len(duplicates)} duplicate groups")
          
          # Generate report
          report = []
          report.append("# üîç Duplicate Files Report\n")
          report.append(f"**Generated:** {Path.ctime(Path.cwd())}\n")
          report.append(f"**Total files scanned:** {total_files}\n")
          report.append(f"**Duplicate groups found:** {len(duplicates)}\n\n")
          
          files_to_delete = []
          
          for file_hash, filepaths in duplicates.items():
              # Sort by priority (highest first)
              sorted_files = sorted(filepaths, key=get_priority, reverse=True)
              
              keep = sorted_files[0]
              delete = sorted_files[1:]
              
              report.append(f"## Hash: `{file_hash[:16]}...`\n")
              report.append(f"**Keep:** `{keep}`\n")
              report.append(f"**Delete ({len(delete)}):**\n")
              
              for dup in delete:
                  report.append(f"- `{dup}`\n")
                  files_to_delete.append(dup)
              
              report.append("\n---\n\n")
          
          # Write report
          with open('DUPLICATE_REPORT.md', 'w', encoding='utf-8') as f:
              f.writelines(report)
          
          print(f"üìÑ Report saved: DUPLICATE_REPORT.md")
          print(f"üóëÔ∏è  Files marked for deletion: {len(files_to_delete)}")
          
          # Delete duplicates
          for filepath in files_to_delete:
              try:
                  os.remove(filepath)
                  print(f"   ‚úì Deleted: {filepath}")
              except Exception as e:
                  print(f"   ‚úó Failed to delete {filepath}: {e}")
          
          print(f"\n‚úÖ Cleanup complete!")
          print(f"üìä Files removed: {len(files_to_delete)}")
          print(f"üìä Files remaining: {total_files - len(files_to_delete)}")
          
          EOF
      
      - name: Commit changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add -A
          git commit -m "chore: remove duplicate files (automated cleanup)" || echo "No changes to commit"
          git push
