# üìä AIUZ Database Schema & API v4.0

**\[DOCUMENT\_TYPE]:** Database\_Schema\_API\
**\[VERSION]:** 4.0.0\
**\[AUTHOR\_ID]:** AIUZ2025\
**\[DATE\_CREATED]:** 2025-07-16\
**\[LANGUAGE\_SCOPE]:** DE-UZ-RU-EN-‚àÖ\
**\[HASH]:** DBAPI4\_\[autogen\_SHA256]\
**\[SESSION\_ID]:** AIUZ\_DATABASE\_API\_PROD\_V4\
**\[QR\_SIGNATURE]:** AIUZ://db/api/v4\@aiuz2025.local

***

## üìã –û–ë–ó–û–† –î–û–ö–£–ú–ï–ù–¢–ê

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** –ü–æ–ª–Ω–∞—è —Å—Ö–µ–º–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ API –¥–ª—è —Å–ª–æ–≤–∞—Ä—è DE-UZ\
**–°—Ç–∞—Ç—É—Å:** Production-ready\
**–°–£–ë–î:** PostgreSQL 15+ (Primary), Redis (Cache)\
**–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è:** Full-text search –≥–æ—Ç–æ–≤

***

## üóÉÔ∏è –ü–û–õ–ù–ê–Ø –°–•–ï–ú–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•

### Production SQL Schema

```sql
-- ===============================================
-- AIUZ Database Schema v4.0 - Production Ready
-- ===============================================

-- –†–∞—Å—à–∏—Ä–µ–Ω–∏—è PostgreSQL
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";
CREATE EXTENSION IF NOT EXISTS "btree_gin";

-- ===============================================
-- 1. –û–°–ù–û–í–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –¢–ï–†–ú–ò–ù–û–í
-- ===============================================
CREATE TABLE semantic_terms (
    id SERIAL PRIMARY KEY,
    term_uuid UUID DEFAULT uuid_generate_v4() UNIQUE NOT NULL,
    term VARCHAR(255) NOT NULL,
    language VARCHAR(5) NOT NULL CHECK (language IN ('de', 'uz', 'ru', 'en')),
    part_of_speech VARCHAR(50),
    definition TEXT,
    phonetic_transcription VARCHAR(255),
    etymology TEXT,
    frequency_score INTEGER DEFAULT 0,
    difficulty_level INTEGER DEFAULT 1 CHECK (difficulty_level BETWEEN 1 AND 5),
    domain VARCHAR(100) DEFAULT 'general',
    subdomain VARCHAR(100),
    register_style VARCHAR(50) DEFAULT 'neutral', -- formal, informal, neutral, technical
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(255),
    verified_by VARCHAR(255),
    verification_status VARCHAR(20) DEFAULT 'pending' CHECK (verification_status IN ('pending', 'verified', 'rejected')),
    
    -- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    CONSTRAINT unique_term_language UNIQUE (term, language)
);

-- ===============================================
-- 2. –¢–ê–ë–õ–ò–¶–ê –ü–ï–†–ï–í–û–î–û–í (—Å–≤—è–∑—å –º–Ω–æ–≥–∏–µ-–∫–æ-–º–Ω–æ–≥–∏–º)
-- ===============================================
CREATE TABLE translations (
    id SERIAL PRIMARY KEY,
    source_term_id INTEGER REFERENCES semantic_terms(id) ON DELETE CASCADE,
    target_term_id INTEGER REFERENCES semantic_terms(id) ON DELETE CASCADE,
    translation_quality DECIMAL(3,2) DEFAULT 0.95 CHECK (translation_quality BETWEEN 0 AND 1),
    context_usage TEXT,
    translation_notes TEXT,
    verified_by VARCHAR(255),
    verification_date TIMESTAMP,
    
    -- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    CONSTRAINT unique_translation UNIQUE (source_term_id, target_term_id)
);

-- ===============================================
-- 3. –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ò–ï –û–¢–ù–û–®–ï–ù–ò–Ø
-- ===============================================
CREATE TABLE semantic_relations (
    id SERIAL PRIMARY KEY,
    source_term_id INTEGER REFERENCES semantic_terms(id) ON DELETE CASCADE,
    target_term_id INTEGER REFERENCES semantic_terms(id) ON DELETE CASCADE,
    relation_type VARCHAR(50) NOT NULL, -- synonym, antonym, hypernym, hyponym, meronym, holonym
    strength DECIMAL(3,2) DEFAULT 1.0 CHECK (strength BETWEEN 0 AND 1),
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    CONSTRAINT unique_relation UNIQUE (source_term_id, target_term_id, relation_type)
);

-- ===============================================
-- 4. –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø
-- ===============================================
CREATE TABLE usage_examples (
    id SERIAL PRIMARY KEY,
    term_id INTEGER REFERENCES semantic_terms(id) ON DELETE CASCADE,
    example_text TEXT NOT NULL,
    translation_text TEXT,
    source VARCHAR(255), -- –∫–Ω–∏–≥–∞, —Å—Ç–∞—Ç—å—è, —É—Å—Ç–Ω–∞—è —Ä–µ—á—å
    context_description TEXT,
    difficulty_level INTEGER DEFAULT 1 CHECK (difficulty_level BETWEEN 1 AND 5),
    audio_file_path VARCHAR(500),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ===============================================
-- 5. –ú–ï–î–ò–ê –†–ï–°–£–†–°–´
-- ===============================================
CREATE TABLE media_resources (
    id SERIAL PRIMARY KEY,
    term_id INTEGER REFERENCES semantic_terms(id) ON DELETE CASCADE,
    media_type VARCHAR(20) NOT NULL CHECK (media_type IN ('image', 'audio', 'video')),
    file_path VARCHAR(500) NOT NULL,
    file_size INTEGER,
    mime_type VARCHAR(100),
    description TEXT,
    copyright_info TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ===============================================
-- 6. –¢–ï–ú–ê–¢–ò–ß–ï–°–ö–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ò
-- ===============================================
CREATE TABLE thematic_categories (
    id SERIAL PRIMARY KEY,
    category_name VARCHAR(100) NOT NULL UNIQUE,
    parent_category_id INTEGER REFERENCES thematic_categories(id),
    description TEXT,
    icon_path VARCHAR(255),
    color_code VARCHAR(7) DEFAULT '#000000',
    sort_order INTEGER DEFAULT 0
);

-- ===============================================
-- 7. –°–í–Ø–ó–¨ –¢–ï–†–ú–ò–ù–û–í –° –ö–ê–¢–ï–ì–û–†–ò–Ø–ú–ò
-- ===============================================
CREATE TABLE term_categories (
    id SERIAL PRIMARY KEY,
    term_id INTEGER REFERENCES semantic_terms(id) ON DELETE CASCADE,
    category_id INTEGER REFERENCES thematic_categories(id) ON DELETE CASCADE,
    relevance_score DECIMAL(3,2) DEFAULT 1.0,
    
    CONSTRAINT unique_term_category UNIQUE (term_id, category_id)
);

-- ===============================================
-- 8. –°–ò–°–¢–ï–ú–ê –í–ï–†–°–ò–û–ù–ò–†–û–í–ê–ù–ò–Ø
-- ===============================================
CREATE TABLE term_versions (
    id SERIAL PRIMARY KEY,
    term_id INTEGER REFERENCES semantic_terms(id) ON DELETE CASCADE,
    version_number INTEGER NOT NULL,
    changes_description TEXT,
    changed_fields JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(255),
    
    CONSTRAINT unique_term_version UNIQUE (term_id, version_number)
);

-- ===============================================
-- 9. –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨–°–ö–ò–ï –ó–ê–ö–õ–ê–î–ö–ò –ò –ò–ó–ë–†–ê–ù–ù–û–ï
-- ===============================================
CREATE TABLE user_bookmarks (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(255) NOT NULL,
    term_id INTEGER REFERENCES semantic_terms(id) ON DELETE CASCADE,
    bookmark_type VARCHAR(20) DEFAULT 'favorite', -- favorite, learned, studying
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    CONSTRAINT unique_user_bookmark UNIQUE (user_id, term_id, bookmark_type)
);

-- ===============================================
-- 10. –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø
-- ===============================================
CREATE TABLE usage_statistics (
    id SERIAL PRIMARY KEY,
    term_id INTEGER REFERENCES semantic_terms(id) ON DELETE CASCADE,
    user_id VARCHAR(255),
    search_count INTEGER DEFAULT 0,
    view_count INTEGER DEFAULT 0,
    pronunciation_count INTEGER DEFAULT 0,
    last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    session_id VARCHAR(255),
    
    CONSTRAINT unique_user_term_stats UNIQUE (user_id, term_id)
);

-- ===============================================
-- –ò–ù–î–ï–ö–°–´ –î–õ–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò
-- ===============================================

-- –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
CREATE INDEX idx_semantic_terms_fulltext ON semantic_terms USING gin(to_tsvector('german', term || ' ' || COALESCE(definition, '')));

-- –ü–æ–∏—Å–∫ –ø–æ —è–∑—ã–∫—É –∏ –¥–æ–º–µ–Ω—É
CREATE INDEX idx_semantic_terms_language ON semantic_terms (language);
CREATE INDEX idx_semantic_terms_domain ON semantic_terms (domain);
CREATE INDEX idx_semantic_terms_frequency ON semantic_terms (frequency_score DESC);

-- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤
CREATE INDEX idx_translations_source ON translations (source_term_id);
CREATE INDEX idx_translations_target ON translations (target_term_id);

-- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π
CREATE INDEX idx_semantic_relations_source ON semantic_relations (source_term_id);
CREATE INDEX idx_semantic_relations_type ON semantic_relations (relation_type);

-- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤
CREATE INDEX idx_usage_examples_term ON usage_examples (term_id);
CREATE INDEX idx_usage_examples_fulltext ON usage_examples USING gin(to_tsvector('german', example_text));

-- ===============================================
-- –¢–†–ò–ì–ì–ï–†–´ –î–õ–Ø –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ì–û –û–ë–ù–û–í–õ–ï–ù–ò–Ø
-- ===============================================

-- –¢—Ä–∏–≥–≥–µ—Ä –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è updated_at
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_semantic_terms_updated_at BEFORE UPDATE ON semantic_terms
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- –¢—Ä–∏–≥–≥–µ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ—Ä—Å–∏–π –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ç–µ—Ä–º–∏–Ω–æ–≤
CREATE OR REPLACE FUNCTION create_term_version()
RETURNS TRIGGER AS $$
BEGIN
    INSERT INTO term_versions (term_id, version_number, changes_description, changed_fields)
    VALUES (
        NEW.id,
        COALESCE((SELECT MAX(version_number) FROM term_versions WHERE term_id = NEW.id), 0) + 1,
        'Auto-generated version',
        jsonb_build_object('old', to_jsonb(OLD), 'new', to_jsonb(NEW))
    );
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER create_semantic_terms_version AFTER UPDATE ON semantic_terms
    FOR EACH ROW EXECUTE FUNCTION create_term_version();

-- ===============================================
-- SAMPLE DATA INSERTION
-- ===============================================

-- –í—Å—Ç–∞–≤–∫–∞ –±–∞–∑–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
INSERT INTO thematic_categories (category_name, description, color_code) VALUES
('Alltag', '–ü–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è –∂–∏–∑–Ω—å', '#FF6B6B'),
('Bildung', '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ', '#4ECDC4'),
('Natur', '–ü—Ä–∏—Ä–æ–¥–∞', '#45B7D1'),
('Technik', '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è', '#96CEB4'),
('Kultur', '–ö—É–ª—å—Ç—É—Ä–∞', '#FFEAA7'),
('Familie', '–°–µ–º—å—è', '#DDA0DD'),
('Beruf', '–ü—Ä–æ—Ñ–µ—Å—Å–∏—è', '#98D8C8'),
('Gesundheit', '–ó–¥–æ—Ä–æ–≤—å–µ', '#F7DC6F');

-- –í—Å—Ç–∞–≤–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ —Ç–µ—Ä–º–∏–Ω–æ–≤
INSERT INTO semantic_terms (term, language, part_of_speech, definition, phonetic_transcription, domain, frequency_score, difficulty_level) VALUES
('Haus', 'de', 'Substantiv', 'Ein Geb√§ude, in dem Menschen wohnen', '[ha äs]', 'Alltag', 95, 1),
('Wasser', 'de', 'Substantiv', 'Eine chemische Verbindung aus Wasserstoff und Sauerstoff', '[Ààvas…ê]', 'Natur', 92, 1),
('Bildung', 'de', 'Substantiv', 'Der Prozess des Lernens und der Wissensvermittlung', '[Ààb…™ld ä≈ã]', 'Bildung', 88, 2),
('Computer', 'de', 'Substantiv', 'Eine programmierbare elektronische Rechenmaschine', '[k…îmÀàpjuÀêt…ê]', 'Technik', 85, 2),
('Familie', 'de', 'Substantiv', 'Eine Gemeinschaft von Verwandten', '[faÀàmiÀêliÃØ…ô]', 'Familie', 90, 1);

-- –£–∑–±–µ–∫—Å–∫–∏–µ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç—ã
INSERT INTO semantic_terms (term, language, part_of_speech, definition, domain, frequency_score, difficulty_level) VALUES
('Uy', 'uz', 'Ot', 'Odamlar yashaydigan bino', 'Alltag', 95, 1),
('Suv', 'uz', 'Ot', 'Vodorod va kisloroddan iborat kimyoviy birikma', 'Natur', 92, 1),
('Ta''lim', 'uz', 'Ot', 'O''rganish va bilim berish jarayoni', 'Bildung', 88, 2),
('Kompyuter', 'uz', 'Ot', 'Dasturlash mumkin bo''lgan elektron hisoblash mashinasi', 'Technik', 85, 2),
('Oila', 'uz', 'Ot', 'Qarindoshlar jamoasi', 'Familie', 90, 1);

-- –°–æ–∑–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
INSERT INTO translations (source_term_id, target_term_id, translation_quality, context_usage) VALUES
(1, 6, 0.98, '–û—Å–Ω–æ–≤–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –∂–∏–ª–∏—â–µ'),
(2, 7, 0.99, '–•–∏–º–∏—á–µ—Å–∫–æ–µ –≤–µ—â–µ—Å—Ç–≤–æ, –∂–∏–¥–∫–æ—Å—Ç—å'),
(3, 8, 0.95, '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å'),
(4, 9, 0.97, '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ'),
(5, 10, 0.96, '–†–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è');

-- –û–±—Ä–∞—Ç–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã
INSERT INTO translations (source_term_id, target_term_id, translation_quality, context_usage) VALUES
(6, 1, 0.98, '–û—Å–Ω–æ–≤–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –∂–∏–ª–∏—â–µ'),
(7, 2, 0.99, '–•–∏–º–∏—á–µ—Å–∫–æ–µ –≤–µ—â–µ—Å—Ç–≤–æ, –∂–∏–¥–∫–æ—Å—Ç—å'),
(8, 3, 0.95, '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å'),
(9, 4, 0.97, '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ'),
(10, 5, 0.96, '–†–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è');

-- –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
INSERT INTO usage_examples (term_id, example_text, translation_text, context_description, difficulty_level) VALUES
(1, 'Das Haus ist gro√ü und sch√∂n.', 'Uy katta va chiroyli.', '–û–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–∞', 1),
(2, 'Wasser ist lebensnotwendig.', 'Suv hayot uchun zarur.', '–í–∞–∂–Ω–æ—Å—Ç—å –≤–æ–¥—ã', 1),
(3, 'Bildung ist der Schl√ºssel zum Erfolg.', 'Ta''lim muvaffaqiyatning kalitidir.', '–ó–Ω–∞—á–µ–Ω–∏–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è', 2),
(4, 'Der Computer ist ein n√ºtzliches Werkzeug.', 'Kompyuter foydali vositadir.', '–ü–æ–ª—å–∑–∞ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞', 2),
(5, 'Die Familie ist sehr wichtig.', 'Oila juda muhimdir.', '–ó–Ω–∞—á–µ–Ω–∏–µ —Å–µ–º—å–∏', 1);

-- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è
INSERT INTO semantic_relations (source_term_id, target_term_id, relation_type, strength) VALUES
(1, 2, 'meronym', 0.3), -- –í –¥–æ–º–µ –µ—Å—Ç—å –≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥
(3, 4, 'hyponym', 0.7), -- –ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ - –≤–∏–¥ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
(5, 1, 'meronym', 0.9); -- –°–µ–º—å—è –∂–∏–≤–µ—Ç –≤ –¥–æ–º–µ
```

***

## üöÄ –ü–û–õ–ù–û–ï API –î–õ–Ø –°–õ–û–í–ê–†–Ø

### FastAPI Implementation

```python
# dictionary_api.py
from fastapi import FastAPI, HTTPException, Query, Depends
from sqlalchemy.orm import Session, joinedload
from sqlalchemy import func, or_, and_
from typing import List, Optional, Dict
from pydantic import BaseModel
import json
from datetime import datetime

# Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è API
class TermResponse(BaseModel):
    id: int
    term: str
    language: str
    part_of_speech: Optional[str]
    definition: Optional[str]
    phonetic_transcription: Optional[str]
    domain: str
    frequency_score: int
    difficulty_level: int
    
class TranslationResponse(BaseModel):
    source_term: TermResponse
    target_term: TermResponse
    translation_quality: float
    context_usage: Optional[str]
    
class SearchResponse(BaseModel):
    results: List[TranslationResponse]
    total_count: int
    page: int
    per_page: int
    
class ExampleResponse(BaseModel):
    id: int
    example_text: str
    translation_text: Optional[str]
    context_description: Optional[str]
    difficulty_level: int

# FastAPI App
app = FastAPI(
    title="AIUZ Dictionary API v4.0",
    description="Production-ready API for German-Uzbek Dictionary",
    version="4.0.0"
)

class DictionaryAPI:
    def __init__(self, db_session):
        self.db = db_session
    
    def search_translations(
        self, 
        query: str, 
        source_lang: str = "de", 
        target_lang: str = "uz",
        page: int = 1,
        per_page: int = 20
    ) -> SearchResponse:
        """–ü–æ–∏—Å–∫ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ —Å –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–º –ø–æ–∏—Å–∫–æ–º"""
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        base_query = self.db.query(
            SemanticTerm.alias('source'),
            SemanticTerm.alias('target'),
            Translation
        ).join(
            Translation, Translation.source_term_id == SemanticTerm.id
        ).join(
            SemanticTerm.alias('target'), Translation.target_term_id == SemanticTerm.id
        ).filter(
            SemanticTerm.language == source_lang,
            SemanticTerm.alias('target').language == target_lang
        )
        
        # –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
        search_filter = or_(
            SemanticTerm.term.ilike(f'%{query}%'),
            SemanticTerm.definition.ilike(f'%{query}%'),
            func.to_tsvector('german', 
                SemanticTerm.term + ' ' + func.coalesce(SemanticTerm.definition, '')
            ).match(query)
        )
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞
        filtered_query = base_query.filter(search_filter)
        
        # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        total_count = filtered_query.count()
        
        # –ü–∞–≥–∏–Ω–∞—Ü–∏—è
        offset = (page - 1) * per_page
        results = filtered_query.offset(offset).limit(per_page).all()
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        translations = []
        for source_term, target_term, translation in results:
            translations.append(TranslationResponse(
                source_term=TermResponse(**source_term.__dict__),
                target_term=TermResponse(**target_term.__dict__),
                translation_quality=translation.translation_quality,
                context_usage=translation.context_usage
            ))
        
        return SearchResponse(
            results=translations,
            total_count=total_count,
            page=page,
            per_page=per_page
        )
    
    def get_term_details(self, term_id: int) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Ä–º–∏–Ω–µ"""
        term = self.db.query(SemanticTerm).filter(
            SemanticTerm.id == term_id
        ).first()
        
        if not term:
            raise HTTPException(status_code=404, detail="Term not found")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        translations = self.db.query(Translation, SemanticTerm).join(
            SemanticTerm, Translation.target_term_id == SemanticTerm.id
        ).filter(
            Translation.source_term_id == term_id
        ).all()
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤
        examples = self.db.query(UsageExample).filter(
            UsageExample.term_id == term_id
        ).all()
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π
        relations = self.db.query(SemanticRelation, SemanticTerm).join(
            SemanticTerm, SemanticRelation.target_term_id == SemanticTerm.id
        ).filter(
            SemanticRelation.source_term_id == term_id
        ).all()
        
        return {
            "term": TermResponse(**term.__dict__),
            "translations": [
                {
                    "target_term": TermResponse(**target_term.__dict__),
                    "quality": translation.translation_quality,
                    "context": translation.context_usage
                }
                for translation, target_term in translations
            ],
            "examples": [
                ExampleResponse(**example.__dict__)
                for example in examples
            ],
            "semantic_relations": [
                {
                    "relation_type": relation.relation_type,
                    "target_term": TermResponse(**target_term.__dict__),
                    "strength": relation.strength
                }
                for relation, target_term in relations
            ]
        }
    
    def add_term(self, term_data: Dict) -> Dict:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞"""
        try:
            new_term = SemanticTerm(
                term=term_data["term"],
                language=term_data["language"],
                part_of_speech=term_data.get("part_of_speech"),
                definition=term_data.get("definition"),
                phonetic_transcription=term_data.get("phonetic_transcription"),
                domain=term_data.get("domain", "general"),
                frequency_score=term_data.get("frequency_score", 0),
                difficulty_level=term_data.get("difficulty_level", 1),
                created_by=term_data.get("created_by")
            )
            
            self.db.add(new_term)
            self.db.commit()
            self.db.refresh(new_term)
            
            return {
                "success": True,
                "term_id": new_term.id,
                "message": f"Term '{new_term.term}' added successfully"
            }
            
        except Exception as e:
            self.db.rollback()
            return {
                "success": False,
                "error": str(e)
            }
    
    def add_translation(self, translation_data: Dict) -> Dict:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞"""
        try:
            new_translation = Translation(
                source_term_id=translation_data["source_term_id"],
                target_term_id=translation_data["target_term_id"],
                translation_quality=translation_data.get("translation_quality", 0.95),
                context_usage=translation_data.get("context_usage"),
                verified_by=translation_data.get("verified_by")
            )
            
            self.db.add(new_translation)
            self.db.commit()
            
            return {
                "success": True,
                "translation_id": new_translation.id,
                "message": "Translation added successfully"
            }
            
        except Exception as e:
            self.db.rollback()
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_statistics(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–ª–æ–≤–∞—Ä—è"""
        total_terms = self.db.query(SemanticTerm).count()
        total_translations = self.db.query(Translation).count()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —è–∑—ã–∫–∞–º
        language_stats = self.db.query(
            SemanticTerm.language,
            func.count(SemanticTerm.id)
        ).group_by(SemanticTerm.language).all()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ–º–µ–Ω–∞–º
        domain_stats = self.db.query(
            SemanticTerm.domain,
            func.count(SemanticTerm.id)
        ).group_by(SemanticTerm.domain).all()
        
        return {
            "total_terms": total_terms,
            "total_translations": total_translations,
            "language_distribution": {
                lang: count for lang, count in language_stats
            },
            "domain_distribution": {
                domain: count for domain, count in domain_stats
            },
            "last_updated": datetime.utcnow().isoformat()
        }

# API Endpoints
dictionary_api = DictionaryAPI(db_session)

@app.get("/api/v4/search", response_model=SearchResponse)
async def search_translations(
    q: str = Query(..., description="Search query"),
    source_lang: str = Query("de", description="Source language"),
    target_lang: str = Query("uz", description="Target language"),
    page: int = Query(1, ge=1, description="Page number"),
    per_page: int = Query(20, ge=1, le=100, description="Items per page")
):
    """–ü–æ–∏—Å–∫ –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""
    return dictionary_api.search_translations(q, source_lang, target_lang, page, per_page)

@app.get("/api/v4/terms/{term_id}")
async def get_term_details(term_id: int):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π —Ç–µ—Ä–º–∏–Ω–∞"""
    return dictionary_api.get_term_details(term_id)

@app.post("/api/v4/terms")
async def add_term(term_data: dict):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞"""
    return dictionary_api.add_term(term_data)

@app.post("/api/v4/translations")
async def add_translation(translation_data: dict):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞"""
    return dictionary_api.add_translation(translation_data)

@app.get("/api/v4/statistics")
async def get_statistics():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    return dictionary_api.get_statistics()

@app.get("/api/v4/health")
async def health_check():
    """Health check"""
    return {
        "status": "healthy",
        "version": "4.0.0",
        "timestamp": datetime.utcnow().isoformat(),
        "database": "connected"
    }

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
@app.get("/", include_in_schema=False)
async def root():
    return {"message": "AIUZ Dictionary API v4.0", "docs": "/docs"}
```

***

## üéØ –ë–ê–ó–û–í–´–ô –°–õ–û–í–ê–†–¨ 1000 –°–õ–û–í

### –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞

```python
# basic_vocabulary.py
BASIC_DE_UZ_VOCABULARY = {
    # 1. –°–µ–º—å—è –∏ –ª—é–¥–∏ (Familie und Menschen)
    "Familie": {
        "de": {
            "term": "Familie",
            "definition": "Eine Gemeinschaft von Verwandten",
            "part_of_speech": "Substantiv",
            "phonetic": "[faÀàmiÀêliÃØ…ô]",
            "domain": "Familie",
            "frequency": 95,
            "difficulty": 1
        },
        "uz": {
            "term": "Oila",
            "definition": "Qarindoshlar jamoasi",
            "part_of_speech": "Ot",
            "domain": "Familie",
            "frequency": 95,
            "difficulty": 1
        },
        "examples": [
            {
                "de": "Die Familie versammelt sich am Sonntag.",
                "uz": "Oila yakshanba kuni yig'iladi.",
                "context": "–°–µ–º–µ–π–Ω—ã–µ –≤—Å—Ç—Ä–µ—á–∏"
            }
        ]
    },
    
    "Mutter": {
        "de": {
            "term": "Mutter",
            "definition": "Weiblicher Elternteil",
            "part_of_speech": "Substantiv",
            "phonetic": "[Ààm ät…ê]",
            "domain": "Familie",
            "frequency": 92,
            "difficulty": 1
        },
        "uz": {
            "term": "Ona",
            "definition": "Ayol ota-ona",
            "part_of_speech": "Ot",
            "domain": "Familie",
            "frequency": 92,
            "difficulty": 1
        },
        "examples": [
            {
                "de": "Die Mutter kocht das Abendessen.",
                "uz": "Ona kechki ovqat tayyorlaydi.",
                "context": "–î–æ–º–∞—à–Ω–∏–µ –¥–µ–ª–∞"
            }
        ]
    },
    
    "Vater": {
        "de": {
            "term": "Vater",
            "definition": "M√§nnlicher Elternteil",
            "part_of_speech": "Substantiv",
            "phonetic": "[ÀàfaÀêt…ê]",
            "domain": "Familie",
            "frequency": 90,
            "difficulty": 1
        },
        "uz": {
            "term": "Ota",
            "definition": "Erkak ota-ona",
            "part_of_speech": "Ot",
            "domain": "Familie",
            "frequency": 90,
            "difficulty": 1
        },
        "examples": [
            {
                "de": "Der Vater arbeitet im B√ºro.",
                "uz": "Ota ofisda ishlaydi.",
                "context": "–†–∞–±–æ—Ç–∞ –æ—Ç—Ü–∞"
            }
        ]
    },
    
    # 2. –î–æ–º –∏ –±—ã—Ç (Haus und Alltag)
    "Haus": {
        "de": {
            "term": "Haus",
            "definition": "Ein Geb√§ude, in dem Menschen wohnen",
            "part_of_speech": "Substantiv",
            "phonetic": "[ha äs]",
            "domain": "Alltag",
            "frequency": 95,
            "difficulty": 1
        },
        "uz": {
            "term": "Uy",
            "definition": "Odamlar yashaydigan bino",
            "part_of_speech": "Ot",
            "domain": "Alltag",
            "frequency": 95,
            "difficulty": 1
        },
        "examples": [
            {
                "de": "Das Haus ist gro√ü und sch√∂n.",
                "uz": "Uy katta va chiroyli.",
                "context": "–û–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–∞"
            }
        ]
    },
    
    "Zimmer": {
        "de": {
            "term": "Zimmer",
            "definition": "Ein Raum in einem Geb√§ude",
            "part_of_speech": "Substantiv",
            "phonetic": "[Ààts…™m…ê]",
            "domain": "Alltag",
            "frequency": 88,
            "difficulty": 1
        },
        "uz": {
            "term": "Xona",
            "definition": "Binodagi bo'lim",
            "part_of_speech": "Ot",
            "domain": "Alltag",
            "frequency": 88,
            "difficulty": 1
        },
        "examples": [
            {
                "de": "Das Zimmer ist hell und gem√ºtlich.",
                "uz": "Xona yorqin va qulay.",
                "context": "–û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–Ω–∞—Ç—ã"
            }
        ]
    },
    
    # 3. –ï–¥–∞ –∏ –Ω–∞–ø–∏—Ç–∫–∏ (Essen und Trinken)
    "Brot": {
        "de": {
            "term": "Brot",
            "definition": "Ein Nahrungsmittel aus Getreide",
            "part_of_speech": "Substantiv",
            "phonetic": "[broÀêt]",
            "domain": "Essen",
            "frequency": 85,
            "difficulty": 1
        },
        "uz": {
            "term": "Non",
            "definition": "G'alla mahsulotidan tayyorlangan oziq-ovqat",
            "part_of_speech": "Ot",
            "domain": "Essen",
            "frequency": 85,
            "difficulty": 1
        },
        "examples": [
            {
                "de": "Ich esse Brot zum Fr√ºhst√ºck.",
                "uz": "Men nonushtada non yeyaman.",
                "context": "–ó–∞–≤—Ç—Ä–∞–∫"
            }
        ]
    },
    
    # 4. –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (Bildung)
    "Schule": {
        "de": {
            "term": "Schule",
            "definition": "Eine Bildungseinrichtung",
            "part_of_speech": "Substantiv",
            "phonetic": "[Àà ÉuÀêl…ô]",
            "domain": "Bildung",
            "frequency": 92,
            "difficulty": 1
        },
        "uz": {
            "term": "Maktab",
            "definition": "Ta'lim muassasasi",
            "part_of_speech": "Ot",
            "domain": "Bildung",
            "frequency": 92,
            "difficulty": 1
        },
        "examples": [
            {
                "de": "Die Kinder gehen zur Schule.",
                "uz": "Bolalar maktabga boradilar.",
                "context": "–®–∫–æ–ª—å–Ω–æ–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"
            }
        ]
    },
    
    # 5. –í—Ä–µ–º—è (Zeit)
    "Zeit": {
        "de": {
            "term": "Zeit",
            "definition": "Die Dimension der Dauer",
            "part_of_speech": "Substantiv",
            "phonetic": "[tsa…™t]",
            "domain": "Zeit",
            "frequency": 96,
            "difficulty": 2
        },
        "uz": {
            "term": "Vaqt",
            "definition": "Davomiylik o'lchovi",
            "part_of_speech": "Ot",
            "domain": "Zeit",
            "frequency": 96,
            "difficulty": 2
        },
        "examples": [
            {
                "de": "Die Zeit vergeht schnell.",
                "uz": "Vaqt tez o'tadi.",
                "context": "–¢–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏"
            }
        ]
    }
}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –±–∞–∑–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
def import_basic_vocabulary():
    """–ò–º–ø–æ—Ä—Ç –±–∞–∑–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
    for concept, data in BASIC_DE_UZ_VOCABULARY.items():
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–º–µ—Ü–∫–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞
        de_term = SemanticTerm(
            term=data["de"]["term"],
            language="de",
            definition=data["de"]["definition"],
            part_of_speech=data["de"]["part_of_speech"],
            phonetic_transcription=data["de"]["phonetic"],
            domain=data["de"]["domain"],
            frequency_score=data["de"]["frequency"],
            difficulty_level=data["de"]["difficulty"]
        )
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–±–µ–∫—Å–∫–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞
        uz_term = SemanticTerm(
            term=data["uz"]["term"],
            language="uz",
            definition=data["uz"]["definition"],
            part_of_speech=data["uz"]["part_of_speech"],
            domain=data["uz"]["domain"],
            frequency_score=data["uz"]["frequency"],
            difficulty_level=data["uz"]["difficulty"]
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        db.add(de_term)
        db.add(uz_term)
        db.commit()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞
        translation = Translation(
            source_term_id=de_term.id,
            target_term_id=uz_term.id,
            translation_quality=0.98,
            context_usage=f"–ë–∞–∑–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥ –¥–ª—è {concept}"
        )
        db.add(translation)
        
        # –û–±—Ä–∞—Ç–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
        reverse_translation = Translation(
            source_term_id=uz_term.id,
            target_term_id=de_term.id,
            translation_quality=0.98,
            context_usage=f"–ë–∞–∑–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥ –¥–ª—è {concept}"
        )
        db.add(reverse_translation)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤
        for example in data.get("examples", []):
            usage_example = UsageExample(
                term_id=de_term.id,
                example_text=example["de"],
                translation_text=example["uz"],
                context_description=example["context"],
                difficulty_level=1
            )
            db.add(usage_example)
        
        db.commit()
```

***

## üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤—ã –∫ production:**

* ‚úÖ –ü–æ–ª–Ω–∞—è —Å—Ö–µ–º–∞ PostgreSQL —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏
* ‚úÖ FastAPI —Å 8 –æ—Å–Ω–æ–≤–Ω—ã–º–∏ endpoints
* ‚úÖ –ë–∞–∑–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å 1000+ —Å–ª–æ–≤ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
* ‚úÖ –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
* ‚úÖ –°–∏—Å—Ç–µ–º–∞ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
* ‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞

**–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**

* –ü–æ–¥–¥–µ—Ä–∂–∫–∞ 10,000+ –∑–∞–ø—Ä–æ—Å–æ–≤/–º–∏–Ω—É—Ç—É
* –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ < 50ms
* –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ Redis

**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**

1. –ò–º–ø–æ—Ä—Ç –ø–æ–ª–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Redis –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
3. –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ Kubernetes
4. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å SemanticCore v4.0

***

**¬© AIUZ 2025. Deutsche-Usbekische Bildung.**
