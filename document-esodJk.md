```python
"""
L2 Trace Œ£ Memory System v1.0
–°–∏—Å—Ç–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏–π Terra Codex
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏ –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
"""

import json
import hashlib
import sqlite3
import pickle
import gzip
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Terra Language Core
from terra_language_core import TerraQuark, TerraNanoCore, TerraMicroCore, TerraLanguageManager

@dataclass
class SessionMetadata:
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏"""
    session_id: str
    user_id: str
    timestamp: str
    terra_version: str
    ethical_level: float
    principles_snapshot: List[str]
    context_hash: str
    
class CompressedMemoryUnit:
    """–°–∂–∞—Ç–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è"""
    
    def __init__(self, data: Any, compression_level: int = 6):
        self.original_size = len(str(data))
        self.compressed_data = gzip.compress(
            pickle.dumps(data), 
            compresslevel=compression_level
        )
        self.compressed_size = len(self.compressed_data)
        self.compression_ratio = self.original_size / self.compressed_size if self.compressed_size > 0 else 1.0
    
    def decompress(self) -> Any:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        return pickle.loads(gzip.decompress(self.compressed_data))
    
    def get_compression_stats(self) -> Dict[str, Any]:
        return {
            "original_size": self.original_size,
            "compressed_size": self.compressed_size,
            "compression_ratio": round(self.compression_ratio, 2),
            "space_saved_percent": round((1 - 1/self.compression_ratio) * 100, 1)
        }

class TerraMemoryDB:
    """–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–∞–º—è—Ç–∏ Terra —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞"""
    
    def __init__(self, db_path: str = "terra_memory.db"):
        self.db = TerraMemoryDB(db_path)
        self.language_manager = TerraLanguageManager()
        self.active_session = None
        self.compression_threshold = 0.7  # –ü–æ—Ä–æ–≥ —Å–∂–∞—Ç–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
    
    def create_session_context(self, user_id: str, terra_principles: List[str]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–∏"""
        timestamp = datetime.now().isoformat()
        context_data = {
            "user_id": user_id,
            "timestamp": timestamp,
            "principles": terra_principles,
            "terra_version": "2.5",
            "session_type": "interactive_learning"
        }
        
        context_hash = hashlib.sha256(json.dumps(context_data, sort_keys=True).encode()).hexdigest()[:16]
        session_id = f"terra_{context_hash}_{timestamp.split('T')[0].replace('-', '')}"
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏
        metadata = SessionMetadata(
            session_id=session_id,
            user_id=user_id,
            timestamp=timestamp,
            terra_version="2.5",
            ethical_level=self._calculate_ethical_level(terra_principles),
            principles_snapshot=terra_principles,
            context_hash=context_hash
        )
        
        self.active_session = {
            "metadata": metadata,
            "microcores": [],
            "start_time": datetime.now(),
            "interaction_count": 0
        }
        
        return session_id
    
    def add_learning_interaction(self, interaction_data: Dict[str, Any]) -> bool:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—É—á–∞—é—â–µ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –≤ —Ç–µ–∫—É—â—É—é —Å–µ—Å—Å–∏—é"""
        if not self.active_session:
            raise ValueError("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏. –°–æ–∑–¥–∞–π—Ç–µ —Å–µ—Å—Å–∏—é —á–µ—Ä–µ–∑ create_session_context()")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–≤–∞—Ä–∫–æ–≤ –∏–∑ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
        quarks = self._extract_quarks_from_interaction(interaction_data)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–Ω–æ—è–¥—Ä–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
        nanocore = self.language_manager.create_nanocore(
            context_type=interaction_data.get("type", "learning_interaction"),
            quarks=quarks,
            ethical_validation=True
        )
        
        # –ü–æ–∏—Å–∫ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –º–∏–∫—Ä–æ—è–¥—Ä–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        microcore = self._find_or_create_microcore(nanocore.context_type)
        microcore.add_nanocore(nanocore)
        
        self.active_session["interaction_count"] += 1
        
        return True
    
    def save_current_session(self) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏"""
        if not self.active_session:
            return False
        
        success = self.db.save_session(
            self.active_session["metadata"],
            self.active_session["microcores"]
        )
        
        if success:
            print(f"‚úÖ –°–µ—Å—Å–∏—è {self.active_session['metadata'].session_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
            print(f"   üìä –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π: {self.active_session['interaction_count']}")
            print(f"   üß¨ –ú–∏–∫—Ä–æ—è–¥–µ—Ä: {len(self.active_session['microcores'])}")
            self.active_session = None
        
        return success
    
    def restore_session(self, session_id: str) -> bool:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –ø–æ ID"""
        result = self.db.load_session(session_id)
        
        if result:
            metadata, microcores = result
            self.active_session = {
                "metadata": metadata,
                "microcores": microcores,
                "start_time": datetime.fromisoformat(metadata.timestamp),
                "interaction_count": sum(len(mc.nanocores) for mc in microcores)
            }
            
            print(f"üîÑ –°–µ—Å—Å–∏—è {session_id} –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
            print(f"   üìÖ –°–æ–∑–¥–∞–Ω–∞: {metadata.timestamp}")
            print(f"   üéØ –≠—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å: {metadata.ethical_level}")
            return True
        
        return False
    
    def search_similar_sessions(self, current_principles: List[str], similarity_threshold: float = 0.6) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–µ—Å—Å–∏–π –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø–∞–º Terra"""
        results = []
        
        for principle in current_principles:
            sessions = self.db.find_sessions_by_principle(principle)
            
            for session_info in sessions:
                similarity = self._calculate_principle_similarity(
                    current_principles, 
                    session_info.get("principles", [])
                )
                
                if similarity >= similarity_threshold:
                    results.append({
                        **session_info,
                        "similarity_score": similarity,
                        "matching_principle": principle
                    })
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        return sorted(results, key=lambda x: x["similarity_score"], reverse=True)
    
    def _calculate_ethical_level(self, principles: List[str]) -> float:
        """–†–∞—Å—á—ë—Ç —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ Terra"""
        ethical_weights = {
            "semantic_modularity": 0.8,
            "adaptive_os": 0.7,
            "child-centric_learning": 1.0,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å
            "ethical_memory": 0.9,
            "knowledge_tokenization": 0.6,
            "decentralized_dao": 0.8,
            "human-nature-symbiosis": 1.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å
        }
        
        if not principles:
            return 0.5  # –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
        
        total_weight = sum(ethical_weights.get(p, 0.5) for p in principles)
        return min(total_weight / len(principles), 1.0)
    
    def _extract_quarks_from_interaction(self, interaction_data: Dict[str, Any]) -> List[TerraQuark]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–≤–∞—Ä–∫–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        quarks = []
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –∫–≤–∞—Ä–∫ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        if "content" in interaction_data:
            content_quark = TerraQuark(
                semantic_id=f"content_{hashlib.md5(str(interaction_data['content']).encode()).hexdigest()[:8]}",
                terra_principle=interaction_data.get("principle", "knowledge_acquisition"),
                ethical_weight=interaction_data.get("ethical_weight", 0.7),
                content_type="text",
                multilingual_data={
                    "ru": interaction_data["content"]
                },
                creation_timestamp=datetime.now().isoformat()
            )
            quarks.append(content_quark)
        
        # –ö–≤–∞—Ä–∫–∏ –∏–∑ –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if "user_actions" in interaction_data:
            for action in interaction_data["user_actions"]:
                action_quark = TerraQuark(
                    semantic_id=f"action_{hashlib.md5(str(action).encode()).hexdigest()[:8]}",
                    terra_principle="adaptive_learning",
                    ethical_weight=0.6,
                    content_type="user_action",
                    multilingual_data={"en": str(action)},
                    creation_timestamp=datetime.now().isoformat()
                )
                quarks.append(action_quark)
        
        return quarks
    
    def _find_or_create_microcore(self, context_type: str) -> TerraMicroCore:
        """–ü–æ–∏—Å–∫ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –º–∏–∫—Ä–æ—è–¥—Ä–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        if not self.active_session:
            raise ValueError("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏")
        
        # –ü–æ–∏—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –º–∏–∫—Ä–æ—è–¥—Ä–∞
        for microcore in self.active_session["microcores"]:
            if context_type in microcore.supported_contexts:
                return microcore
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –º–∏–∫—Ä–æ—è–¥—Ä–∞
        new_microcore = self.language_manager.create_microcore(
            name=f"microcore_{context_type}",
            version="2.5",
            supported_contexts=[context_type]
        )
        
        self.active_session["microcores"].append(new_microcore)
        return new_microcore
    
    def _calculate_principle_similarity(self, principles1: List[str], principles2: List[str]) -> float:
        """–†–∞—Å—á—ë—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –Ω–∞–±–æ—Ä–∞–º–∏ –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤"""
        if not principles1 or not principles2:
            return 0.0
        
        set1, set2 = set(principles1), set(principles2)
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        
        return intersection / union if union > 0 else 0.0
    
    def get_session_analytics(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏"""
        if not self.active_session:
            return {"error": "–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏"}
        
        duration = datetime.now() - self.active_session["start_time"]
        
        return {
            "session_id": self.active_session["metadata"].session_id,
            "duration_minutes": duration.total_seconds() / 60,
            "interactions_count": self.active_session["interaction_count"],
            "microcores_count": len(self.active_session["microcores"]),
            "ethical_level": self.active_session["metadata"].ethical_level,
            "principles": self.active_session["metadata"].principles_snapshot,
            "estimated_memory_size": self._estimate_session_size()
        }
    
    def _estimate_session_size(self) -> Dict[str, int]:
        """–û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏ –≤ –ø–∞–º—è—Ç–∏"""
        if not self.active_session:
            return {"total_bytes": 0}
        
        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
        metadata_size = len(json.dumps(asdict(self.active_session["metadata"])))
        microcores_size = sum(
            len(str(mc.export_to_dict())) for mc in self.active_session["microcores"]
        )
        
        return {
            "metadata_bytes": metadata_size,
            "microcores_bytes": microcores_size,
            "total_bytes": metadata_size + microcores_size,
            "compression_potential": self._estimate_compression_potential()
        }
    
    def _estimate_compression_potential(self) -> float:
        """–û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ —Å–∂–∞—Ç–∏—è –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏"""
        # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö Terra
        return self.compression_threshold


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏
if __name__ == "__main__":
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ø–∞–º—è—Ç–∏
    memory_manager = TraceMemoryManager()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    session_id = memory_manager.create_session_context(
        user_id="terra_user_001",
        terra_principles=[
            "child-centric_learning",
            "ethical_memory", 
            "human-nature-symbiosis"
        ]
    )
    
    print(f"üöÄ –°–æ–∑–¥–∞–Ω–∞ —Å–µ—Å—Å–∏—è: {session_id}")
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
    interactions = [
        {
            "type": "educational_content",
            "content": "–ò–∑—É—á–µ–Ω–∏–µ —ç–∫–æ—Å–∏—Å—Ç–µ–º—ã –ª–µ—Å–∞ —á–µ—Ä–µ–∑ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—É—é —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å",
            "principle": "human-nature-symbiosis",
            "ethical_weight": 0.9,
            "user_actions": ["vr_exploration", "tree_identification", "ecosystem_mapping"]
        },
        {
            "type": "collaborative_learning",
            "content": "–°–æ–≤–º–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–µ–∫—Ç —Å –¥–µ—Ç—å–º–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞–Ω",
            "principle": "child-centric_learning",
            "ethical_weight": 1.0,
            "user_actions": ["cross_cultural_communication", "project_collaboration"]
        }
    ]
    
    for interaction in interactions:
        memory_manager.add_learning_interaction(interaction)
    
    # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å–µ—Å—Å–∏–∏
    analytics = memory_manager.get_session_analytics()
    print(f"üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å–µ—Å—Å–∏–∏: {analytics}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏
    memory_manager.save_current_session()
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Å–µ—Å—Å–∏–π
    similar_sessions = memory_manager.search_similar_sessions([
        "child-centric_learning",
        "human-nature-symbiosis"
    ])
    
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö —Å–µ—Å—Å–∏–π: {len(similar_sessions)}")
    
    print("\nüß¨ L2 Trace Œ£ Memory System v1.0 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    print("‚úÖ –ì–æ—Ç–æ–≤–∞ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –ø–æ–ª–Ω–æ–π —ç–∫–æ—Å–∏—Å—Ç–µ–º–æ–π Terra Codex v2.5")_path = db_path
        self.init_database()
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # –¢–∞–±–ª–∏—Ü–∞ —Å–µ—Å—Å–∏–π
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sessions (
                session_id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                terra_version TEXT NOT NULL,
                ethical_level REAL NOT NULL,
                principles_snapshot TEXT NOT NULL,
                context_hash TEXT NOT NULL,
                metadata_json TEXT NOT NULL
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –º–∏–∫—Ä–æ—è–¥–µ—Ä (—Å–∂–∞—Ç—ã—Ö)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS microcores (
                microcore_id TEXT PRIMARY KEY,
                session_id TEXT NOT NULL,
                name TEXT NOT NULL,
                version TEXT NOT NULL,
                compressed_data BLOB NOT NULL,
                compression_stats TEXT NOT NULL,
                created_at TEXT NOT NULL,
                FOREIGN KEY (session_id) REFERENCES sessions (session_id)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø–∞–º
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS principle_index (
                principle_name TEXT NOT NULL,
                session_id TEXT NOT NULL,
                microcore_id TEXT NOT NULL,
                ethical_weight REAL NOT NULL,
                context_type TEXT NOT NULL,
                PRIMARY KEY (principle_name, session_id, microcore_id)
            )
        ''')
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_sessions_user_time ON sessions (user_id, timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_microcores_session ON microcores (session_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_principle_name ON principle_index (principle_name)')
        
        conn.commit()
        conn.close()
    
    def save_session(self, session_metadata: SessionMetadata, microcores: List[TerraMicroCore]) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Å –∫–æ–º–ø—Ä–µ—Å—Å–∏–µ–π"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏
            cursor.execute('''
                INSERT OR REPLACE INTO sessions 
                (session_id, user_id, timestamp, terra_version, ethical_level, 
                 principles_snapshot, context_hash, metadata_json)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                session_metadata.session_id,
                session_metadata.user_id,
                session_metadata.timestamp,
                session_metadata.terra_version,
                session_metadata.ethical_level,
                json.dumps(session_metadata.principles_snapshot),
                session_metadata.context_hash,
                json.dumps(asdict(session_metadata))
            ))
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∏–∫—Ä–æ—è–¥–µ—Ä
            for microcore in microcores:
                # –ö–æ–º–ø—Ä–µ—Å—Å–∏—è –º–∏–∫—Ä–æ—è–¥—Ä–∞
                compressed_unit = CompressedMemoryUnit(microcore.export_to_dict())
                
                cursor.execute('''
                    INSERT OR REPLACE INTO microcores
                    (microcore_id, session_id, name, version, compressed_data, 
                     compression_stats, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    microcore.id,
                    session_metadata.session_id,
                    microcore.name,
                    microcore.version,
                    compressed_unit.compressed_data,
                    json.dumps(compressed_unit.get_compression_stats()),
                    microcore.created_at
                ))
                
                # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
                for nanocore in microcore.nanocores:
                    for quark in nanocore.quarks:
                        cursor.execute('''
                            INSERT OR REPLACE INTO principle_index
                            (principle_name, session_id, microcore_id, ethical_weight, context_type)
                            VALUES (?, ?, ?, ?, ?)
                        ''', (
                            quark.terra_principle,
                            session_metadata.session_id,
                            microcore.id,
                            quark.ethical_weight,
                            nanocore.context_type
                        ))
            
            conn.commit()
            conn.close()
            return True
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏: {e}")
            return False
    
    def load_session(self, session_id: str) -> Optional[Tuple[SessionMetadata, List[TerraMicroCore]]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–µ—Å—Å–∏–∏ —Å –¥–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏–µ–π"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            cursor.execute('SELECT * FROM sessions WHERE session_id = ?', (session_id,))
            session_row = cursor.fetchone()
            
            if not session_row:
                return None
            
            # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            metadata = SessionMetadata(
                session_id=session_row[0],
                user_id=session_row[1],
                timestamp=session_row[2],
                terra_version=session_row[3],
                ethical_level=session_row[4],
                principles_snapshot=json.loads(session_row[5]),
                context_hash=session_row[6]
            )
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–∏–∫—Ä–æ—è–¥–µ—Ä
            cursor.execute('SELECT * FROM microcores WHERE session_id = ?', (session_id,))
            microcore_rows = cursor.fetchall()
            
            microcores = []
            for row in microcore_rows:
                # –î–µ–∫–æ–º–ø—Ä–µ—Å—Å–∏—è –¥–∞–Ω–Ω—ã—Ö
                compressed_data = row[4]
                decompressed_data = pickle.loads(gzip.decompress(compressed_data))
                
                # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∏–∫—Ä–æ—è–¥—Ä–∞ (—É–ø—Ä–æ—â—ë–Ω–Ω–æ–µ)
                # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –ø–æ–ª–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞
                microcore_dict = decompressed_data
                # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ TerraMicroCore –∏–∑ dict
                
            conn.close()
            return metadata, microcores
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ—Å—Å–∏–∏: {e}")
            return None
    
    def find_sessions_by_principle(self, principle_name: str, days_back: int = 30) -> List[str]:
        """–ü–æ–∏—Å–∫ —Å–µ—Å—Å–∏–π –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É Terra"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cutoff_date = (datetime.now() - timedelta(days=days_back)).isoformat()
            
            cursor.execute('''
                SELECT DISTINCT pi.session_id, s.timestamp, s.ethical_level
                FROM principle_index pi
                JOIN sessions s ON pi.session_id = s.session_id
                WHERE pi.principle_name = ? AND s.timestamp >= ?
                ORDER BY s.timestamp DESC
            ''', (principle_name, cutoff_date))
            
            results = cursor.fetchall()
            conn.close()
            
            return [{"session_id": r[0], "timestamp": r[1], "ethical_level": r[2]} for r in results]
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É: {e}")
            return []

class TraceMemoryManager:
    """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ–Ω–µ–¥–∂–µ—Ä —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏ Trace Œ£"""
    
    def __init__(self, db_path: str = "terra_memory.db"):
        self.db
```
